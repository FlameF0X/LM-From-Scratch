# LM-From-Scratch

Inspired after [pingvortex/Learn-ML](https://github.com/pingvortex/Learn-ML)
---
You will learn the following:
1. What is a pre-train modeland the difference between pre-train and fine-tunr models.
2. How Pre-Training Works: Under the Hood
3. Step-by-Step: Building a Language Model from Scratch
   - Collecting and cleaning your corpus
   - Training a tokenizer
   - Designing your model (hidden size, layers, etc.)
   - Choosing and implementing the loss function
   - Training loop and hardware setup
   - Checkpointing and monitoring
   - Evaluating pre-training progress (e.g., perplexity)

---
## Documented topic:
1. What is a pre-train modeland the difference between pre-train and fine-tunr models. ✅
2. How Pre-Training Works: Under the Hood ✅
3. Step-by-Step: Building a Language Model from Scratch ✅
   - Data Collection & Processing ✅
   - Tokenization: Building the Vocabulary ✅
   - Model Architecture Design
   - Pre-Training Objectives
   - Infrastructure & Training Environment
   - Optimization & Training Loop
   - Monitoring & Evaluation
---
### START HERE >>> [WHAT IS A PRE-TRAIN MODEL](doc-1/what-is-a-pre-train-model.md)
